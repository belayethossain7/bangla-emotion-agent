{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph langchain-community langchain-openai tavily-python"
      ],
      "metadata": {
        "id": "ZdLQptkaV_G3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "\n",
        "_set_env(\"\")\n",
        "_set_env(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "qZTOhghNWIdm",
        "outputId": "9117434e-c20f-4b41-ea98-791e0a2d4f65"
      },
      "execution_count": 41,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ": 路路路路路路路路路路\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 22] Invalid argument",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-608268361.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0m_set_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0m_set_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-608268361.py\u001b[0m in \u001b[0;36m_set_env\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_set_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{var}: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 22] Invalid argument"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "jP2-vBNraB7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "#tools = [TavilySearchResults(max_results=3)]\n",
        "\n",
        "tools = [TavilySearchResults(tavily_api_key=\"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\", max_results=3)]"
      ],
      "metadata": {
        "id": "dsrn7t9cWttt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_openai import ChatOpenAI\n",
        "\n",
        "# from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# # Choose the LLM that will drive the agent\n",
        "# llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
        "# prompt = \"You are a helpful assistant.\"\n",
        "# agent_executor = create_react_agent(llm, tools, prompt=prompt)\n",
        "\n",
        "\n",
        "\n",
        "#####################################\n",
        "\n",
        "\n",
        "# Install required packages if not already installed\n",
        "# !pip install -U langchain-openai langchain-tavily langgraph\n",
        "\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "#  Set your keys\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-your-openai-key-here\"   # <-- replace with your OpenAI key\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
        "\n",
        "#  Tavily search tool\n",
        "tools = [TavilySearchResults(max_results=3)]\n",
        "\n",
        "#  LLM (OpenAI GPT model)\n",
        "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
        "\n",
        "#  Create the agent\n",
        "prompt = \"You are a helpful assistant.\"\n",
        "agent_executor = create_react_agent(llm, tools, prompt=prompt)\n",
        "\n",
        "#  Run the agent with a query\n",
        "response = agent_executor.invoke({\"input\": \"Search the latest updates about AI in 2025\"})\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "SJ_0MGBzWw2_",
        "outputId": "b5ffc882-e755-4624-c7e8-6d0cb310f2ec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-your-***********here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3937418762.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#  Run the agent with a query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Search the latest updates about AI in 2025\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3024\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3026\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   3027\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2645\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2648\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    163\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/prebuilt/chat_agent_executor.py\u001b[0m in \u001b[0;36mcall_model\u001b[0;34m(state, runtime, config)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAIMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAIMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;31m# add agent name to the AIMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5493\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5494\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5495\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5496\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5497\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         return cast(\n\u001b[1;32m    392\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    394\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1018\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m                 results.append(\n\u001b[0;32m--> 837\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    838\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraw_response\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"http_response\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_response\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m         if (\n\u001b[1;32m   1185\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_response_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 )\n\u001b[1;32m   1177\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                 \u001b[0mraw_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_raw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_legacy_response.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extra_headers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLegacyAPIResponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-your-***********here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, List, Tuple\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "class PlanExecute(TypedDict):\n",
        "    input: str\n",
        "    plan: List[str]\n",
        "    past_steps: Annotated[List[Tuple], operator.add]\n",
        "    response: str"
      ],
      "metadata": {
        "id": "ibPCuty_W66m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class Plan(BaseModel):\n",
        "    \"\"\"Plan to follow in future\"\"\"\n",
        "\n",
        "    steps: List[str] = Field(\n",
        "        description=\"different steps to follow, should be in sorted order\"\n",
        "    )"
      ],
      "metadata": {
        "id": "RWHiOAP5XM2G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "planner_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
        "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
        "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\"\"\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{messages}\"),\n",
        "    ]\n",
        ")\n",
        "normalizer = planner_prompt | ChatOpenAI(\n",
        "    model=\"gpt-4o\", temperature=0\n",
        ").with_structured_output(Plan)"
      ],
      "metadata": {
        "id": "tlOTqmDsXP12"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            (\"user\", \"what is stress?\")\n",
        "        ]\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "rWK66Z69XTYm",
        "outputId": "2d7a997b-4780-4d0c-d92e-2920bf411afa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-your-***********here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1658989955.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m normalizer.invoke(\n\u001b[0m\u001b[1;32m      2\u001b[0m     {\n\u001b[1;32m      3\u001b[0m         \"messages\": [\n\u001b[1;32m      4\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"what is stress?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5493\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5494\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5495\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5496\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5497\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         return cast(\n\u001b[1;32m    392\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    394\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1018\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m                 results.append(\n\u001b[0;32m--> 837\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    838\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraw_response\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"http_response\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_response\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m         if (\n\u001b[1;32m   1185\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_response_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                     raw_response = (\n\u001b[0;32m-> 1151\u001b[0;31m                         self.root_client.chat.completions.with_raw_response.parse(\n\u001b[0m\u001b[1;32m   1152\u001b[0m                             \u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m                         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_legacy_response.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extra_headers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLegacyAPIResponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, safety_identifier, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    181\u001b[0m             )\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-your-***********here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union\n",
        "\n",
        "\n",
        "class Response(BaseModel):\n",
        "    \"\"\"Response to user.\"\"\"\n",
        "\n",
        "    response: str\n",
        "\n",
        "\n",
        "class Act(BaseModel):\n",
        "    \"\"\"Action to perform.\"\"\"\n",
        "\n",
        "    action: Union[Response, Plan] = Field(\n",
        "        description=\"Action to perform. If you want to respond to user, use Response. \"\n",
        "        \"If you need to further use tools to get the answer, use Plan.\"\n",
        "    )\n",
        "\n",
        "\n",
        "replanner_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
        "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
        "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
        "\n",
        "Your objective was this:\n",
        "{input}\n",
        "\n",
        "Your original plan was this:\n",
        "{plan}\n",
        "\n",
        "You have currently done the follow steps:\n",
        "{past_steps}\n",
        "\n",
        "Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "replanner = replanner_prompt | ChatOpenAI(\n",
        "    model=\"gpt-4o\", temperature=0\n",
        ").with_structured_output(Act)"
      ],
      "metadata": {
        "id": "llm9w-JRXWUm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "from langgraph.graph import END\n",
        "\n",
        "\n",
        "async def execute_step(state: PlanExecute):\n",
        "    plan = state[\"plan\"]\n",
        "    plan_str = \"\\n\".join(f\"{i + 1}. {step}\" for i, step in enumerate(plan))\n",
        "    task = plan[0]\n",
        "    task_formatted = f\"\"\"For the following plan:\n",
        "{plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
        "    agent_response = await agent_executor.ainvoke(\n",
        "        {\"messages\": [(\"user\", task_formatted)]}\n",
        "    )\n",
        "    return {\n",
        "        \"past_steps\": [(task, agent_response[\"messages\"][-1].content)],\n",
        "    }\n",
        "\n",
        "\n",
        "async def plan_step(state: PlanExecute):\n",
        "    plan = await normalizer.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
        "    return {\"plan\": plan.steps}\n",
        "\n",
        "\n",
        "async def replan_step(state: PlanExecute):\n",
        "    output = await replanner.ainvoke(state)\n",
        "    if isinstance(output.action, Response):\n",
        "        return {\"response\": output.action.response}\n",
        "    else:\n",
        "        return {\"plan\": output.action.steps}\n",
        "\n",
        "\n",
        "def should_end(state: PlanExecute):\n",
        "    if \"response\" in state and state[\"response\"]:\n",
        "        return END\n",
        "    else:\n",
        "        return \"agent\""
      ],
      "metadata": {
        "id": "tfJrtUPxXhl_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START\n",
        "\n",
        "workflow = StateGraph(PlanExecute)\n",
        "\n",
        "# Add the plan node\n",
        "workflow.add_node(\"normalizer\", plan_step)\n",
        "\n",
        "# Add the execution step\n",
        "workflow.add_node(\"agent\", execute_step)\n",
        "\n",
        "# Add a replan node\n",
        "workflow.add_node(\"next-agent\", replan_step)\n",
        "\n",
        "workflow.add_edge(START, \"normalizer\")\n",
        "\n",
        "# From plan we go to agent\n",
        "workflow.add_edge(\"normalizer\", \"agent\")\n",
        "\n",
        "# From agent, we replan\n",
        "workflow.add_edge(\"agent\", \"next-agent\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"next-agent\",\n",
        "    # Next, we pass in the function that will determine which node is called next.\n",
        "    should_end,\n",
        "    [\"agent\", END],\n",
        ")\n",
        "\n",
        "# Finally, we compile it!\n",
        "# This compiles it into a LangChain Runnable,\n",
        "# meaning you can use it as you would any other runnable\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "0WeK_cwEXl-O"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "45BpmOxiXq1G",
        "outputId": "ed189552-0587-49a3-fbcc-88b6226146c2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"recursion_limit\": 50}\n",
        "inputs = {\"input\": \"what about stress?\"}\n",
        "async for event in app.astream(inputs, config=config):\n",
        "    for k, v in event.items():\n",
        "        if k != \"__end__\":\n",
        "            print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "Tq4rbmBQYtBv",
        "outputId": "db0b8d0a-a494-4f1c-ba70-a2dac0663b7a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-your-***********here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4068091517.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"recursion_limit\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"what about stress?\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"__end__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mastream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2937\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2938\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2939\u001b[0;31m                     async for _ in runner.atick(\n\u001b[0m\u001b[1;32m   2940\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36matick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 await arun_with_retry(\n\u001b[0m\u001b[1;32m    296\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    704\u001b[0m                         \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                         \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                             input = await asyncio.create_task(\n\u001b[0m\u001b[1;32m    707\u001b[0m                                 \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0;32mawait\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2999317188.py\u001b[0m in \u001b[0;36mplan_step\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplan_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPlanExecute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mplan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"plan\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mplan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3122\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3123\u001b[0m                         \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3124\u001b[0;31m                     \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcoro_with_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3125\u001b[0m             \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3126\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5506\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5507\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5508\u001b[0;31m         return await self.bound.ainvoke(\n\u001b[0m\u001b[1;32m   5509\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5510\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m     ) -> BaseMessage:\n\u001b[1;32m    414\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         llm_result = await self.agenerate_prompt(\n\u001b[0m\u001b[1;32m    416\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36magenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1029\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m         return await self.agenerate(\n\u001b[0m\u001b[1;32m   1031\u001b[0m             \u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36magenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    986\u001b[0m                     ]\n\u001b[1;32m    987\u001b[0m                 )\n\u001b[0;32m--> 988\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m         flattened_outputs = [\n\u001b[1;32m    990\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_agenerate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agenerate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m             result = await self._agenerate(\n\u001b[0m\u001b[1;32m   1159\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_agenerate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraw_response\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"http_response\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_response\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m         if (\n\u001b[1;32m   1431\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_response_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_agenerate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1390\u001b[0m                 \u001b[0mpayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m                     raw_response = await self.root_async_client.chat.completions.with_raw_response.parse(  # noqa: E501\n\u001b[0m\u001b[1;32m   1393\u001b[0m                         \u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_legacy_response.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extra_headers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLegacyAPIResponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, safety_identifier, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1617\u001b[0m             )\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m         return await self._post(\n\u001b[0m\u001b[1;32m   1620\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m             body=await async_maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0masync_to_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m         )\n\u001b[0;32m-> 1794\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m     async def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1594\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-your-***********here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ]
    }
  ]
}